{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusers=['julie', 'eva', 'rebecca', 'cinthia', 'caroline','ariel', 'lynn', 'judith']\n",
    "musers=['josh', 'jake', 'matthew', 'luke', 'aaron', 'ted']\n",
    "chat1=[]\n",
    "chat2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing data\n",
    "f=open(\"data/Mar07_GroupB.txt\",\"r\")\n",
    "for line in f:\n",
    "    x=line.split(\"):\")\n",
    "    u=x[0].split()[0]\n",
    "    if u==\"moderator\":\n",
    "      continue\n",
    "    sentence=x[1].strip()\n",
    "    chat1.append((u,sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"data/Mar06_GroupA.txt\",\"r\")\n",
    "for line in f:\n",
    "    x=line.split(\"):\")\n",
    "    u=x[0].split()[0]\n",
    "    if u==\"moderator\":\n",
    "      continue\n",
    "    sentence=x[1].strip()\n",
    "    chat2.append((u,sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"data/English_ANEW_long_DEFT.txt\",\"r\")\n",
    "anew={}\n",
    "x=5\n",
    "for line in f:\n",
    "    if(x!=0):\n",
    "        x-=1\n",
    "        continue\n",
    "    temp=line.split()\n",
    "    anew[temp[2]]=float(temp[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#core nlp lib spaCy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word lists from https://elib.uni-stuttgart.de/bitstream/11682/9665/1/ausarbeitung.pdf\n",
    "diminishers=[\"almost\",\"barely\",\"bit\",\"exiguous\",\"faintly\",\"fairly\",\"few\",\"fewer\",\"hardly\",\"insignificantly\",\"kinda\",\"less\",\"little\",\"maybe\",\"marginally\",\"moderately\",\"modicum\",\"mostly\",\"nearly\",\"negligibly\",\"partly\",\"partially\",\"practically\",\"quite\",\"rather\",\"rarely\",\"relatively\",\"reasonably\",\"scanty\",\"scarcely\",\"slightly\",\"some\",\"somewhat\",\"sparsely\",\"tolerably\",\"triflingly\",\"virtually\"]\n",
    "intensifiers=[\"absolutely\",\"altogether\",\"amazingly\",\"astoundingly\",\"awfully\",\"badly\",\"decidedly\",\"bitterly\",\"bloody\",\"colossally\",\"completely\",\"damn\",\"deeply\",\"drastically\",\"dreadfully\",\"entirely\",\"enormously\",\"especially\",\"exceptionally\",\"excessively\",\"extraordinarily\",\"extremely\",\"fantastically\",\"freaking\",\"frightfully\",\"fucking\",\"fully\",\"greatly\",\"hella\",\"highly\",\"incredibly\",\"insanely\",\"intensely\",\"immensely\",\"largely\",\"literally\",\"lot\",\"lots\",\"massive\",\"mightily\",\"more\",\"outrageously\",\"particularly\",\"perfectly\",\"phenomenally\",\"pretty\",\"radically\",\"real\",\"really\",\"remarkably\",\"purely\",\"so\",\"soo\",\"sooo\",\"super\",\"supremely\",\"surpassingly\",\"strikingly\",\"strongly\",\"terribly\",\"terrifically\",\"totally\",\"thoroughly\",\"truly\",\"unusually\",\"utterly\",\"very\",\"wicked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for easier access to counts + avg polarity\n",
    "class entry:\n",
    "    def __init__(self,c,val):\n",
    "        self.count=c\n",
    "        self.lst=[val]\n",
    "    def __str__(self):\n",
    "        return str(self.count)+':'+str(self.lst)\n",
    "    def __repr__(self):\n",
    "        return str(self.count)+':'+str(self.lst)\n",
    "    def __lt__(self, other):\n",
    "        return self.count<other.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main calc for chats, chat1 for the users-message dictionary, p is the list of proper nouns (only for chat)\n",
    "def calc(chat1,p):\n",
    "    fchat={}\n",
    "    mchat={}\n",
    "    propers=p\n",
    "    lastProper=\"\"\n",
    "    lastNoun=\"\"\n",
    "    for message in chat1:\n",
    "        doc = nlp(message[1])\n",
    "        nouns=[]\n",
    "        pronouns=[]\n",
    "        proNounReplacers=[]\n",
    "        for token in doc:\n",
    "            #find noun subjects\n",
    "            if \"nsubj\" == token.dep_:\n",
    "                #pronoun replacement\n",
    "                if \"PRON\"== token.pos_:\n",
    "                    if token.text.lower()==\"she\" or token.text.lower()==\"he\":\n",
    "                        if(token.text.lower() in pronouns):\n",
    "                            proNounReplacers.append(proNounReplacers[pronouns.index(token.text.lower())])\n",
    "                        else:\n",
    "                            proNounReplacers.append(lastProper)\n",
    "                            pronouns.append(token.text.lower())\n",
    "                    elif token.text.lower()==\"it\":\n",
    "                        proNounReplacers.append(lastNoun)\n",
    "                    if(token.text.lower()!=\"i\"):\n",
    "                        nouns.append(token)\n",
    "                #keeping track of new nouns and proper nouns to use in pronoun replacement\n",
    "                elif \"PROPN\"== token.pos_ and token.text.lower() in propers:\n",
    "                    lastProper=token.text.lower()\n",
    "                    nouns.append(token)\n",
    "                else:\n",
    "                    lastNoun=token.text.lower()\n",
    "                    nouns.append(token)\n",
    "            elif \"PROPN\"== token.pos_ and token.text.lower() in propers:\n",
    "                    lastProper=token.text.lower()\n",
    "            elif \"NOUN\"== token.pos_:\n",
    "                lastNoun=token.text\n",
    "                \n",
    "        #if len(proNounReplacers)!=0:\n",
    "        #    print(proNounReplacers)\n",
    "        \n",
    "        #iterate through the identified subjects\n",
    "        for noun in nouns:\n",
    "                if noun.head.pos_==\"NOUN\":\n",
    "                    pass\n",
    "                #look at noun and its head, english in S-V-O structure, looking at stuff of V\n",
    "                queue=[noun.head,noun]\n",
    "                #interesting an relevant words\n",
    "                coolwords=[]\n",
    "                #tree traversal\n",
    "                while(len(queue)!=0):\n",
    "                    node=queue.pop(0)\n",
    "                    # only add adjectives, adverbs, negation, and attributes\n",
    "                    if node.pos_==\"ADV\" or node.pos_==\"ADJ\" or node.dep_==\"attr\" or node.dep_==\"neg\":\n",
    "                        coolwords.append(node)\n",
    "                    for child in node.children:\n",
    "                        if child!=noun and child.dep_!=\"ROOT\":\n",
    "                            queue.append(child)\n",
    "                #print(noun.text+\" \"+str(coolwords))\n",
    "                \n",
    "                numIntensifiers=0\n",
    "                numDiminishers=0\n",
    "                polarity=0.0\n",
    "                count=0\n",
    "                #compute polarity of words associated with the subject\n",
    "                for word in coolwords:\n",
    "                    temp=word.text.lower()\n",
    "                    if temp in intensifiers:\n",
    "                        numIntensifiers+=1\n",
    "                    elif temp in diminishers:\n",
    "                        numDiminishers+=1\n",
    "                    else:\n",
    "                        #look in anew, if not foun tried the lemmatized version\n",
    "                        if temp in anew.keys():\n",
    "                            polarity+=anew[temp]\n",
    "                            count+=1\n",
    "                        elif word.lemma_.lower() in anew.keys():\n",
    "                            polarity+=anew[word.lemma_.lower()]\n",
    "                            count+=1\n",
    "                #print(numIntensifiers)\n",
    "                #print(numDiminishers)\n",
    "                if(count!=0):\n",
    "                    #computer average polarity\n",
    "                    polarity=polarity/count\n",
    "                    if(polarity!=5.0):\n",
    "                        #add intensifier and diminsher influences\n",
    "                        direction=(polarity-5)/abs(polarity-5)\n",
    "                        polarity+=(.2*numIntensifiers*direction)\n",
    "                        polarity+=(-.2*numDiminishers*direction)\n",
    "                    else:\n",
    "                        polarity=5.0\n",
    "                        \n",
    "                if(polarity!=0.0):\n",
    "                    polarity-=5\n",
    "                    polarity=abs(polarity)\n",
    "                #replace the pronoun before storing\n",
    "                if(len(pronouns)>=1 and noun.text.lower()==pronouns[0]):\n",
    "                    pronouns.pop(0)\n",
    "                    temp=proNounReplacers.pop(0)\n",
    "                else:\n",
    "                    temp=noun.text.lower()\n",
    "                #store the data\n",
    "                if(temp!=None):\n",
    "                    if(message[0] in fusers):\n",
    "                        if(message[0] in fchat.keys()):\n",
    "                            if(temp in fchat[message[0]].keys()):\n",
    "                                fchat[message[0]][temp].count+=1\n",
    "                                fchat[message[0]][temp].lst.append(polarity)\n",
    "                            else:\n",
    "                                fchat[message[0]][temp]=entry(1,polarity)\n",
    "                        else:\n",
    "                            fchat[message[0]]={}\n",
    "                            fchat[message[0]][temp]=entry(1,polarity)\n",
    "                    else:\n",
    "                        if(message[0] in mchat.keys()):\n",
    "                            if(temp in mchat[message[0]].keys()):\n",
    "                                mchat[message[0]][temp].count+=1\n",
    "                                mchat[message[0]][temp].lst.append(polarity)\n",
    "                            else:\n",
    "                                mchat[message[0]][temp]=entry(1,polarity)\n",
    "                        else:\n",
    "                            mchat[message[0]]={}\n",
    "                            mchat[message[0]][temp]=entry(1,polarity)   \n",
    "    return (fchat,mchat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1\n",
      "1.231325072463768\n",
      "0.8457546398046398\n",
      "0.7267456790123455\n",
      "m1\n",
      "0.8579449333333332\n",
      "0.9151500000000001\n",
      "0.43073947368421056\n",
      "f1\n",
      "0.8091413333333334\n",
      "0.5163308823529412\n",
      "1.0245846666666667\n",
      "1.0822920454545453\n",
      "0.7764652173913043\n",
      "f2\n",
      "0.8668381944444445\n",
      "0.9134348214285714\n",
      "0.6631181818181818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nresults:\\n{'lynn': 1.2293985507246374, 'ariel': 0.7148748473748474, 'judith': 0.7030864197530865}\\n{'aaron': 0.8020800000000001, 'luke': 0.8881250000000002, 'ted': 0.34986842105263155}\\n\\n{'julie': 0.8397333333333333, 'caroline': 0.460735294117647, 'rebecca': 1.0081333333333335, 'eva': 1.0427272727272725, 'cinthia': 0.5882608695652174}\\n{'josh': 0.8320138888888889, 'jake': 0.9204166666666669, 'matthew': 0.48727272727272736}\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=calc(chat1,[\"jade\",\"penny\",\"ryan\",\"evan\"])\n",
    "fchat=x[0]\n",
    "mchat=x[1]\n",
    "#compute average polarity on topics per each user\n",
    "fresults={}\n",
    "for user in fchat.keys():\n",
    "    sum=0\n",
    "    for topic in fchat[user].keys():\n",
    "        subsum=0\n",
    "        for x in fchat[user][topic].lst:\n",
    "            subsum+=x\n",
    "        if((fchat[user][topic].count-fchat[user][topic].lst.count(0.0))!=0):\n",
    "            #remove topics mentions that have no sentiment\n",
    "            avg=subsum/(fchat[user][topic].count-fchat[user][topic].lst.count(0.0))\n",
    "            sum+=avg+(fchat[user][topic].count/100)*avg\n",
    "    fresults[user]=sum/len(fchat[user].keys())\n",
    "print(\"f1\")\n",
    "for val in fresults.values():\n",
    "    print(val)\n",
    "\n",
    "#repeated as above\n",
    "mresults={}\n",
    "for user in mchat.keys():\n",
    "    sum=0\n",
    "    for topic in mchat[user].keys():\n",
    "        subsum=0\n",
    "        for x in mchat[user][topic].lst:\n",
    "            subsum+=x\n",
    "        if((mchat[user][topic].count-mchat[user][topic].lst.count(0.0))!=0):\n",
    "            avg=subsum/(mchat[user][topic].count-mchat[user][topic].lst.count(0.0))\n",
    "            sum+=avg+(mchat[user][topic].count/100)*avg\n",
    "    mresults[user]=sum/len(mchat[user].keys())\n",
    "print(\"m1\")\n",
    "for val in mresults.values():\n",
    "    print(val)\n",
    "\n",
    "x=calc(chat2,[\"alan\",\"dwight\",\"clark\",\"brent\"])\n",
    "fchat=x[0]\n",
    "mchat=x[1]\n",
    "fresults={}\n",
    "for user in fchat.keys():\n",
    "    sum=0\n",
    "    for topic in fchat[user].keys():\n",
    "        subsum=0\n",
    "        for x in fchat[user][topic].lst:\n",
    "            subsum+=x\n",
    "        if((fchat[user][topic].count-fchat[user][topic].lst.count(0.0))!=0):\n",
    "            avg=subsum/(fchat[user][topic].count-fchat[user][topic].lst.count(0.0))\n",
    "            sum+=avg+(fchat[user][topic].count/100)*avg\n",
    "    fresults[user]=sum/len(fchat[user].keys())\n",
    "print(\"f2\")\n",
    "for val in fresults.values():\n",
    "    print(val)\n",
    "\n",
    "mresults={}\n",
    "for user in mchat.keys():\n",
    "    sum=0\n",
    "    for topic in mchat[user].keys():\n",
    "        subsum=0\n",
    "        for x in mchat[user][topic].lst:\n",
    "            subsum+=x\n",
    "        if((mchat[user][topic].count-mchat[user][topic].lst.count(0.0))!=0):\n",
    "            avg=subsum/(mchat[user][topic].count-mchat[user][topic].lst.count(0.0))\n",
    "            sum+=avg+(mchat[user][topic].count/100)*avg\n",
    "    mresults[user]=sum/len(mchat[user].keys())\n",
    "print(\"m2\")\n",
    "for val in mresults.values():\n",
    "    print(val)\n",
    "'''\n",
    "results:\n",
    "f1\n",
    "1.231325072463768\n",
    "0.8457546398046398\n",
    "0.7267456790123455\n",
    "m1\n",
    "0.8579449333333332\n",
    "0.9151500000000001\n",
    "0.43073947368421056\n",
    "f1\n",
    "0.8091413333333334\n",
    "0.5163308823529412\n",
    "1.0245846666666667\n",
    "1.0822920454545453\n",
    "0.7764652173913043\n",
    "m2\n",
    "0.8668381944444445\n",
    "0.9134348214285714\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using twitter data\n",
    "import pandas as pd\n",
    "import io\n",
    "data = pd.read_csv('data/gender-classifier-DFE-791531.csv',encoding = \"ISO-8859-1\")\n",
    "data.head(1)\n",
    "data=data.drop(columns=['tweet_count', 'gender:confidence', 'description', 'fav_number', 'link_color', 'name', 'retweet_count', 'sidebar_color', \"_unit_id\",\"_unit_state\",\"_golden\",\"_trusted_judgments\",\"_last_judgment_at\",\"profile_yn\",\"profile_yn:confidence\",\"created\",\"profile_yn_gold\",\"profileimage\",\"gender_gold\",\"tweet_id\",\"tweet_location\",\"user_timezone\",\"tweet_coord\",\"tweet_created\"],axis=1)\n",
    "#delete non gendered rows\n",
    "for index,row in data.iterrows():\n",
    "  if row['gender']!='male' and row['gender']!='female':\n",
    "    data.drop(index,inplace=True)\n",
    "dataDict=data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fchat={}\n",
    "mchat={}\n",
    "lastProper=\"\"\n",
    "lastNoun=\"\"\n",
    "#same as before, but with no pronoun name lists\n",
    "for index in dataDict['gender'].keys():\n",
    "    doc = nlp(dataDict['text'][index])\n",
    "    nouns=[]\n",
    "    pronouns=[]\n",
    "    proNounReplacers=[]\n",
    "    for token in doc:\n",
    "        if \"nsubj\" == token.dep_:\n",
    "            if \"PRON\"== token.pos_:\n",
    "                if token.text.lower()==\"she\" or token.text.lower()==\"he\":\n",
    "                    if(token.text.lower() in pronouns):\n",
    "                        proNounReplacers.append(proNounReplacers[pronouns.index(token.text.lower())])\n",
    "                    else:\n",
    "                        proNounReplacers.append(lastProper)\n",
    "                        pronouns.append(token.text.lower())\n",
    "                elif token.text.lower()==\"it\":\n",
    "                    proNounReplacers.append(lastNoun)\n",
    "                if(token.text.lower()!=\"i\"):\n",
    "                    nouns.append(token)\n",
    "            elif \"PROPN\"== token.pos_ :\n",
    "                lastProper=token.text.lower()\n",
    "                nouns.append(token)\n",
    "            else:\n",
    "                lastNoun=token.text.lower()\n",
    "                nouns.append(token)\n",
    "        elif \"PROPN\"== token.pos_:\n",
    "                lastProper=token.text.lower()\n",
    "        elif \"NOUN\"== token.pos_:\n",
    "            lastNoun=token.text\n",
    "\n",
    "    for noun in nouns:\n",
    "            if noun.head.pos_==\"NOUN\":\n",
    "                pass\n",
    "            queue=[noun.head,noun]\n",
    "            coolwords=[]\n",
    "            while(len(queue)!=0):\n",
    "                node=queue.pop(0)\n",
    "                if node.pos_==\"ADV\" or node.pos_==\"ADJ\" or node.dep_==\"attr\" or node.dep_==\"neg\":\n",
    "                    coolwords.append(node)\n",
    "                for child in node.children:\n",
    "                    if child!=noun and child.dep_!=\"ROOT\":\n",
    "                        queue.append(child)\n",
    "            #print(noun.text+\" \"+str(coolwords))\n",
    "            numIntensifiers=0\n",
    "            numDiminishers=0\n",
    "            polarity=0.0\n",
    "            count=0\n",
    "            for word in coolwords:\n",
    "                temp=word.text.lower()\n",
    "                if temp in intensifiers:\n",
    "                    numIntensifiers+=1\n",
    "                elif temp in diminishers:\n",
    "                    numDiminishers+=1\n",
    "                else:\n",
    "                    if temp in anew.keys():\n",
    "                        polarity+=anew[temp]\n",
    "                        count+=1\n",
    "                    elif word.lemma_.lower() in anew.keys():\n",
    "                        polarity+=anew[word.lemma_.lower()]\n",
    "                        count+=1\n",
    "            #print(numIntensifiers)\n",
    "            #print(numDiminishers)\n",
    "            if(count!=0):\n",
    "                polarity=polarity/count\n",
    "                if(polarity!=5.0):\n",
    "                    direction=(polarity-5)/abs(polarity-5)\n",
    "                    #print(direction)\n",
    "                    polarity+=(.2*numIntensifiers*direction)\n",
    "                    polarity+=(-.2*numDiminishers*direction)\n",
    "                else:\n",
    "                    polarity=5.0\n",
    "            if(polarity!=0.0):\n",
    "                polarity-=5\n",
    "                polarity=abs(polarity)\n",
    "            if(len(pronouns)>=1 and noun.text.lower()==pronouns[0]):\n",
    "                pronouns.pop(0)\n",
    "                temp=proNounReplacers.pop(0)\n",
    "            else:\n",
    "                temp=noun.text.lower()\n",
    "            if(temp!=None):\n",
    "                if(dataDict['gender'][index]==\"female\"):\n",
    "                    if(index in fchat.keys()):\n",
    "                        if(temp in fchat[index].keys()):\n",
    "                            fchat[index][temp].count+=1\n",
    "                            fchat[index][temp].lst.append(polarity)\n",
    "                        else:\n",
    "                            fchat[index][temp]=entry(1,polarity)\n",
    "                    else:\n",
    "                        fchat[index]={}\n",
    "                        fchat[index][temp]=entry(1,polarity)\n",
    "                else:\n",
    "                    if(index in mchat.keys()):\n",
    "                        if(temp in mchat[index].keys()):\n",
    "                            mchat[index][temp].count+=1\n",
    "                            mchat[index][temp].lst.append(polarity)\n",
    "                        else:\n",
    "                            mchat[index][temp]=entry(1,polarity)\n",
    "                    else:\n",
    "                        mchat[index]={}\n",
    "                        mchat[index][temp]=entry(1,polarity)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2640142275494708\n",
      "1.1645548289199301\n"
     ]
    }
   ],
   "source": [
    "#same as before\n",
    "fresults={}\n",
    "for user in fchat.keys():\n",
    "    sum=0\n",
    "    for topic in fchat[user].keys():\n",
    "        subsum=0\n",
    "        for x in fchat[user][topic].lst:\n",
    "            subsum+=x\n",
    "        if((fchat[user][topic].count-fchat[user][topic].lst.count(0.0))!=0):\n",
    "            avg=subsum/(fchat[user][topic].count-fchat[user][topic].lst.count(0.0))\n",
    "            sum+=avg+(fchat[user][topic].count/100)*avg\n",
    "    fresults[user]=sum/len(fchat[user].keys())\n",
    "\n",
    "mresults={}\n",
    "for user in mchat.keys():\n",
    "    sum=0\n",
    "    for topic in mchat[user].keys():\n",
    "        subsum=0\n",
    "        for x in mchat[user][topic].lst:\n",
    "            subsum+=x\n",
    "        if((mchat[user][topic].count-mchat[user][topic].lst.count(0.0))!=0):\n",
    "            avg=subsum/(mchat[user][topic].count-mchat[user][topic].lst.count(0.0))\n",
    "            sum+=avg+(mchat[user][topic].count/100)*avg\n",
    "    mresults[user]=sum/len(mchat[user].keys())\n",
    "\n",
    "#remove users with no detected polarity in tweet\n",
    "favg=0\n",
    "count1=0\n",
    "for user in fresults.keys():\n",
    "    favg+=fresults[user]\n",
    "    if fresults[user]==0:\n",
    "        count1+=1\n",
    "favg/=len(fresults.keys())-count1\n",
    "\n",
    "mavg=0\n",
    "count2=0\n",
    "for user in mresults.keys():\n",
    "    mavg+=mresults[user]\n",
    "    if mresults[user]==0:\n",
    "        count2+=1\n",
    "mavg/=len(mresults.keys())-count2\n",
    "\n",
    "print(favg)\n",
    "\n",
    "print(mavg)\n",
    "\n",
    "#F with 0's: 0.5698763670166223\n",
    "#M with 0's: 0.5486616276140085\n",
    "#F without 0's: 1.2472353997127799\n",
    "#M without 0's: 1.1472725356935882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a47d8c5e56b043b494e7d85c69993360-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">max</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">cool</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">mack</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">bad</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a47d8c5e56b043b494e7d85c69993360-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a47d8c5e56b043b494e7d85c69993360-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a47d8c5e56b043b494e7d85c69993360-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a47d8c5e56b043b494e7d85c69993360-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a47d8c5e56b043b494e7d85c69993360-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a47d8c5e56b043b494e7d85c69993360-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a47d8c5e56b043b494e7d85c69993360-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a47d8c5e56b043b494e7d85c69993360-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a47d8c5e56b043b494e7d85c69993360-0-4\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a47d8c5e56b043b494e7d85c69993360-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a47d8c5e56b043b494e7d85c69993360-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a47d8c5e56b043b494e7d85c69993360-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max [cool, bad]\n",
      "mack [bad]\n"
     ]
    }
   ],
   "source": [
    "#showcase\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy import displacy\n",
    "doc = nlp(\"max is cool and mack is bad\")\n",
    "displacy.render(doc, style='dep')\n",
    "nouns=[]\n",
    "pronouns=[]\n",
    "proNounReplacers=[]\n",
    "lastProper=\"\"\n",
    "lastNoun=\"\"\n",
    "for token in doc:\n",
    "    if \"nsubj\" == token.dep_:\n",
    "        if \"PRON\"== token.pos_:\n",
    "            if token.text.lower()==\"she\" or token.text.lower()==\"he\":\n",
    "                if(token.text.lower() in pronouns):\n",
    "                    proNounReplacers.append(proNounReplacers[pronouns.index(token.text.lower())])\n",
    "                else:\n",
    "                    proNounReplacers.append(lastProper)\n",
    "                    pronouns.append(token.text.lower())\n",
    "            elif token.text.lower()==\"it\":\n",
    "                proNounReplacers.append(lastNoun)\n",
    "            if(token.text.lower()!=\"i\"):\n",
    "                nouns.append(token)\n",
    "        elif \"PROPN\"== token.pos_ :\n",
    "            lastProper=token.text.lower()\n",
    "            nouns.append(token)\n",
    "        else:\n",
    "            lastNoun=token.text.lower()\n",
    "            nouns.append(token)\n",
    "    elif \"PROPN\"== token.pos_:\n",
    "            lastProper=token.text.lower()\n",
    "    elif \"NOUN\"== token.pos_:\n",
    "        lastNoun=token.text\n",
    "\n",
    "for noun in nouns:\n",
    "        if noun.head.pos_==\"NOUN\":\n",
    "            pass\n",
    "        queue=[noun.head,noun]\n",
    "        coolwords=[]\n",
    "        while(len(queue)!=0):\n",
    "            node=queue.pop(0)\n",
    "            if node.pos_==\"ADV\" or node.pos_==\"ADJ\" or node.dep_==\"attr\" or node.dep_==\"neg\":\n",
    "                coolwords.append(node)\n",
    "            for child in node.children:\n",
    "                if child!=noun and child.dep_!=\"ROOT\":\n",
    "                    queue.append(child)\n",
    "        print(noun.text+\" \"+str(coolwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
